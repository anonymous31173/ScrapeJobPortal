{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as ur\n",
    "import urllib\n",
    "\n",
    "\n",
    "url='http://www.naukri.com/information-technology-jobs?qi%5B%5D=25'\n",
    "html=ur.urlopen(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bt=BeautifulSoup(html.read(),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alljobs = bt.find_all(\"div\", class_=\"row \")\n",
    "len(alljobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "# To make this complete - we should run the next loop thru alljobs[0] till alljobs[25] (or whatever the length is)\n",
    "for element in alljobs[0]:\n",
    "    i=i+1\n",
    "    \n",
    "    #print(\"i:\",i)\n",
    "    #print(element)\n",
    "    if i==2:\n",
    "        #print(\"Hello****\")\n",
    "        #    print(\"Hello\")\n",
    "        #print( element.prettify())\n",
    "        link2job=element.get('href')\n",
    "        desig = element.find_all(\"span\", class_=\"desig\")[0].text\n",
    "        org = element.find_all(\"span\", class_=\"org\")[0].text\n",
    "        exp = element.find_all(\"span\", class_=\"exp\")[0].text\n",
    "        loc = element.find_all(\"span\", class_=\"loc\")[0].text\n",
    "        shortdes = element.find_all(\"span\", class_=\"desc\")[0].text\n",
    "        #tmpstr= element.find_all(\"div\", class_=\"other_details\")[0]\n",
    "    #print('******')\n",
    "    if i==8:\n",
    "        # Get jobid, postedby, salary, and when was it posted?\n",
    "        jobid = element.find_all(\"span\", class_=\"action savejob fav \")[0][\"jid\"]\n",
    "        #postedby = element.find_all(\"span\", class_=\"rec_details\")[0].text\n",
    "        postedby=element.a[\"title\"]\n",
    "        salary = element.find_all(\"span\", class_=\"salary\")[0].text\n",
    "        postingdate = element.find_all(\"span\", class_=\"date\")[0].text\n",
    "        \n",
    "print (\"link2job :\" + link2job )\n",
    "print(\"Designation: \" + desig)\n",
    "print(\"Organization \" + org)\n",
    "print(\"Experience: \" + exp)\n",
    "print(\"Location: \" + loc)\n",
    "print(\"Short Description: \" + shortdes)\n",
    "print(\"JobId: \" + jobid)\n",
    "print(\"postedby: \" + postedby)\n",
    "print(\"salary: \" + salary)\n",
    "print(\"postingdate: \" + postingdate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request as ur\n",
    "httpResponse=ur.urlopen(link2job)\n",
    "print(httpResponse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html1=httpResponse.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bt1=BeautifulSoup(html1,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experienceRequirements = bt1.find('span', itemprop='experienceRequirements').contents\n",
    "title1=bt1.find('h1', itemprop='title').contents[1]\n",
    "hiringOrganization=bt1.find('a', itemprop='hiringOrganization').text\n",
    "loc=bt1.find('div',itemprop='name').text\n",
    "sal=bt1.find('div',class_='sumFoot').span.next.next.next.next.text\n",
    "whenposted=bt1.find('div',class_='sumFoot').span.next.next.next.next.next.next.next.next.text\n",
    "description=bt1.find('ul', itemprop='description').text\n",
    "sal1=bt1.find('div', class_='jDisc mt20').span.text + bt1.find('div', class_='jDisc mt20').span.next.next.next.text\n",
    "\n",
    "industry=bt1.find('div', class_='jDisc mt20').span.next.next.next.next.next.next.next.next.text\n",
    "funcarea=bt1.find('div', class_='jDisc mt20').span.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next.text\n",
    "\n",
    "sal1=bt1.find('div', class_='jDisc mt20').span.text + bt1.find('div', class_='jDisc mt20').span.next.next.next.text\n",
    "skills=\"\"\n",
    "for skls in bt1.find_all('span', itemprop='skills'):\n",
    "    skills=skills+skls.text+';'\n",
    "\n",
    "print(skills)\n",
    "print(experienceRequirements)\n",
    "print(title1)\n",
    "print(hiringOrganization)\n",
    "print(loc)\n",
    "print(sal)\n",
    "print(whenposted)\n",
    "print(description)\n",
    "print(sal1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bt1.find('div', class_='jDisc mt20').span.next.next.next.next.next.next.next.next.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
